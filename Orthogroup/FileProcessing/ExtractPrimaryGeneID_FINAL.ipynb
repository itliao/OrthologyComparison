{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 231109\n",
    "# to upload on github\n",
    "# to get list of primary transcript IDs and create files of the list of primary transcripts\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main path\n",
    "gff_path = r\"/path_to_gff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to gff3 files or protein files (Arabidopsis only)\n",
    "#Thlaspi not included - were all primary transcripts\n",
    "\n",
    "Aar_gff_path = gff_path + \"/Ae.arabicum_v3.1_annotations_utr.gff\" \n",
    "Bra_gff_path = gff_path + \"/BrapaFPsc_277_v1.3.gene_exons.gff3\" \n",
    "Chi_gff_path = gff_path + \"/carhr38.gff\" \n",
    "\n",
    "Cru_gff_path = gff_path + \"/Crubella_474_v1.1.gene_exons.gff3\" \n",
    "Csa_gff_path = gff_path + \"/Camelina_sativa.Cs.55.chr.gff3\" \n",
    "Sal_gff_path = gff_path + \"/Sinapis/Sal.Chr.20210627.gff\" \n",
    "\n",
    "Ath_fa_path = gff_path + \"/Athaliana_447_Araport11.protein_primaryTranscriptOnly.fa\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below: using regular expressions for each -> return a list of primary gene IDs\n",
    "# assume -1 is the longest protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aethionema\n",
    "Aar_file = open(Aar_gff_path, \"r\")\n",
    "Aar_regex = r\"[a-zA-Z0-9]{10,14}\\-[a-zA-Z]{4}\\-[1]\"\n",
    "Aar_list = [list(set(re.findall(Aar_regex, line))) for line in Aar_file] \n",
    "Aar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arabidopsis\n",
    "Ath_file = open(Ath_fa_path, \"r\")\n",
    "Ath_regex = r\"[a-zA-Z0-9]{9}\\.[0-9]*\\.[a-zA-Z0-9]{9}\\.[0-9]{3}\"\n",
    "Ath_list = [list(set(re.findall(Ath_regex, line))) for line in Ath_file]\n",
    "Ath_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brassica\n",
    "Bra_file = open(Bra_gff_path, \"r\")\n",
    "Bra_regex = \"[a-zA-Z]{5}\\.[a-zA-Z0-9]{6}\\.[1]\\.[<v][1]\\.[3]\"\n",
    "Bra_list = [list(set(re.findall(Bra_regex, line))) for line in Bra_file]\n",
    "Bra_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cardamine\n",
    "Chi_file = open(Chi_gff_path, \"r\")\n",
    "Chi_regex = \"[a-zA-Z0-9]{11}\\.[1]\"\n",
    "Chi_list = [list(set(re.findall(Chi_regex, line))) for line in Chi_file]\n",
    "Chi_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capsella\n",
    "Cru_file = open(Cru_gff_path, \"r\")\n",
    "Cru_regex = \"[a-zA-Z]{5}\\.[a-zA-Z0-9]{9}\\.[1]\\.[<v][1]\\.[1]\"\n",
    "Cru_list = [list(set(re.findall(Cru_regex, line))) for line in Cru_file]\n",
    "Cru_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camelina\n",
    "Csa_file = open(Csa_gff_path, \"r\")\n",
    "Csa_regex = \"[a-zA-Z]{10}\\:[a-zA-Z0-9]{12}\\.[1]\"\n",
    "Csa_list = [list(set(re.findall(Csa_regex, line))) for line in Csa_file]\n",
    "Csa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sinapis - part 1\n",
    "#cannot have SalContig456\n",
    "Sal_file = open(Sal_gff_path, \"r\") \n",
    "Sal_regex = \"[a-zA-Z]{3}[0-9]{2}[a-zA-Z0-9]{7}\"\n",
    "Sal_list1 = [list(set(re.findall(Sal_regex, line))) for line in Sal_file]\n",
    "Sal_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sinapis - part 2\n",
    "Sal_file = open(Sal_gff_path, \"r\")\n",
    "Sal_regex = \"[a-zA-Z]{9}\\_[a-zA-Z0-9]{6}\"\n",
    "Sal_list2 = [list(set(re.findall(Sal_regex, line))) for line in Sal_file]\n",
    "Sal_list2\n",
    "\n",
    "Sal_list = Sal_list1 + Sal_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert List to dataframe, remove duplicates, write to new file \n",
    "output_path = gff_path + \"/primaryTranscriptID\"\n",
    "\n",
    "def df_noDup_List(geneIDList, species):\n",
    "    df = pd.DataFrame(geneIDList)\n",
    "    df_noDup = df.drop_duplicates()\n",
    "    #df_ID = df_noDup.drop([0]) \n",
    "    df_noDup.to_csv(output_path+\"/\"+species+\"_primaryGeneID.txt\", header = False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to create files of the list of primary transcripts\n",
    "\n",
    "df_noDup_List(Aar_list, \"Aar\")\n",
    "df_noDup_List(Ath_list, \"Ath\")\n",
    "df_noDup_List(Bra_list, \"Bra\")\n",
    "df_noDup_List(Chi_list, \"Chi\")\n",
    "df_noDup_List(Cru_list, \"Cru\")\n",
    "df_noDup_List(Csa_list, \"Csa\")\n",
    "df_noDup_List(Sal_list, \"Sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
