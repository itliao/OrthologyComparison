{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975ff170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6358908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "main_path = r\"/path_to_files\"\n",
    "test_file = main_path + \"/comparison/240209_full/test_metrics.csv\"\n",
    "dip_file = main_path + \"/comparison/240212_diploid/diploid_pairwiseMetrics_240212.csv\"\n",
    "full_file = main_path + \"/comparison/240209_full/full_pairwiseMetrics_240209.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081f951d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene</th>\n",
       "      <th>program1</th>\n",
       "      <th>program2</th>\n",
       "      <th>RS</th>\n",
       "      <th>ARS</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>p1_num_AT</th>\n",
       "      <th>p1_AT_genes</th>\n",
       "      <th>p2_num_AT</th>\n",
       "      <th>p2_AT_genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AT1G31370.1</td>\n",
       "      <td>BR</td>\n",
       "      <td>OFb</td>\n",
       "      <td>0.12536723465626837</td>\n",
       "      <td>0.0012752262772070281</td>\n",
       "      <td>12</td>\n",
       "      <td>194</td>\n",
       "      <td>0.061855670103092786</td>\n",
       "      <td>26</td>\n",
       "      <td>AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....</td>\n",
       "      <td>4</td>\n",
       "      <td>AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AT1G31370.1</td>\n",
       "      <td>BR</td>\n",
       "      <td>OFd</td>\n",
       "      <td>0.11292131830564607</td>\n",
       "      <td>0.0006154338653651564</td>\n",
       "      <td>15</td>\n",
       "      <td>194</td>\n",
       "      <td>0.07731958762886598</td>\n",
       "      <td>26</td>\n",
       "      <td>AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....</td>\n",
       "      <td>4</td>\n",
       "      <td>AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AT1G31370.1</td>\n",
       "      <td>BR</td>\n",
       "      <td>OFm</td>\n",
       "      <td>0.08685433470434271</td>\n",
       "      <td>-0.00021956134779301637</td>\n",
       "      <td>17</td>\n",
       "      <td>194</td>\n",
       "      <td>0.08762886597938144</td>\n",
       "      <td>26</td>\n",
       "      <td>AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....</td>\n",
       "      <td>4</td>\n",
       "      <td>AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AT1G31370.1</td>\n",
       "      <td>BR</td>\n",
       "      <td>SPd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AT1G31370.1</td>\n",
       "      <td>BR</td>\n",
       "      <td>SPm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         gene program1 program2                   RS  \\\n",
       "0           0  AT1G31370.1       BR      OFb  0.12536723465626837   \n",
       "1           1  AT1G31370.1       BR      OFd  0.11292131830564607   \n",
       "2           2  AT1G31370.1       BR      OFm  0.08685433470434271   \n",
       "3           3  AT1G31370.1       BR      SPd                  NaN   \n",
       "4           4  AT1G31370.1       BR      SPm                  NaN   \n",
       "\n",
       "                       ARS intersection union               Jaccard  \\\n",
       "0    0.0012752262772070281           12   194  0.061855670103092786   \n",
       "1    0.0006154338653651564           15   194   0.07731958762886598   \n",
       "2  -0.00021956134779301637           17   194   0.08762886597938144   \n",
       "3                      NaN            0   193                   0.0   \n",
       "4                      NaN            0   193                   0.0   \n",
       "\n",
       "   p1_num_AT                                        p1_AT_genes  p2_num_AT  \\\n",
       "0         26  AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....          4   \n",
       "1         26  AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....          4   \n",
       "2         26  AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....          4   \n",
       "3         26  AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....          0   \n",
       "4         26  AT3G58420.1,AT3G58270.3,AT3G58380.1,AT3G58260....          0   \n",
       "\n",
       "                                       p2_AT_genes  \n",
       "0  AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1  \n",
       "1  AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1  \n",
       "2  AT1G31390.1;AT1G31400.1;AT1G31380.1;AT1G31370.1  \n",
       "3                                              NaN  \n",
       "4                                              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_t = pd.read_csv(test_file)\n",
    "metrics_t.replace('na', np.nan, inplace=True)\n",
    "metrics_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea64111",
   "metadata": {},
   "source": [
    "## Remove duplicate entries from comparisons with BR outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9724a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 1: to remove the duplicate entries\n",
    "# for BR - find the one that has the highest Jaccard value - likely the correct comparison with BR\n",
    "# reason for this - BR will assign a gene to multiple clusters depending on its segments\n",
    "\n",
    "def removeDuplicateEntries(subset):\n",
    "    uniqueEntries = {}\n",
    "    uniqueGene = []\n",
    "    duplicateEntries = {}\n",
    "    \n",
    "    subset[[\"Jaccard\"]] = subset[[\"Jaccard\"]].apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    for index, row in subset.iterrows():\n",
    "        #key1 = (row[2], row[3])\n",
    "        ATgene = row[1]\n",
    "        \n",
    "        if ATgene not in uniqueGene:\n",
    "            uniqueGene.append(ATgene)\n",
    "\n",
    "            geneSubset = subset[(subset[\"gene\"] == ATgene)]\n",
    "\n",
    "            for index, row in geneSubset.iterrows():\n",
    "                key1 = (row[2], row[3])\n",
    "                keySubset = geneSubset[(geneSubset[\"program1\"] == row[2]) & (geneSubset[\"program2\"] == row[3])]\n",
    "                \n",
    "                if keySubset.shape[0] == 1:\n",
    "                    if key1 not in uniqueEntries:\n",
    "                        uniqueEntries[key1] = [keySubset]\n",
    "                    else:\n",
    "                        uniqueEntries[key1].append(keySubset)\n",
    "\n",
    "                else:\n",
    "                    #print(keySubset)\n",
    "                    #keySubset[[\"Jaccard\"]] = keySubset[[\"Jaccard\"]].apply(pd.to_numeric, errors='ignore')\n",
    "                    maxJaccard = keySubset.nlargest(1,['Jaccard'])\n",
    "                    #print(maxJaccard)\n",
    "                    if key1 not in uniqueEntries:\n",
    "                        uniqueEntries[key1] = [maxJaccard]\n",
    "                    else:\n",
    "                        uniqueEntries[key1].append(maxJaccard)\n",
    "                    \n",
    "                    if key1 not in duplicateEntries:\n",
    "                        duplicateEntries[key1] = [ATgene]\n",
    "                    else:\n",
    "                        duplicateEntries[key1].append(ATgene)\n",
    "                        \n",
    "    return(uniqueEntries, uniqueGene, duplicateEntries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictEntries_d, uniqueList_d, duplicateDict_d = removeDuplicateEntries(subset_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check which ones have duplicate entries\n",
    "for pairKey, metricRow in duplicateDict_d.items():\n",
    "    print(pairKey)\n",
    "    print(metricRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fd328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of the new dataframe without duplicate entries\n",
    "def newMetricsDF(dictEntries):\n",
    "    listOfDF = []\n",
    "    for pairKey, metricRow in dictEntries.items():\n",
    "        print(pairKey)\n",
    "        columnNames = list(subset_d.columns)\n",
    "        progPairDF = pd.concat(metricRow)\n",
    "        progPairDF_nodup = progPairDF.drop_duplicates(subset=progPairDF.columns.difference(['Unnamed: 0']))\n",
    "        listOfDF.append(progPairDF_nodup)\n",
    "        print(progPairDF.shape)\n",
    "        print(progPairDF_nodup.shape)\n",
    "    \n",
    "    newMetrics = pd.concat(listOfDF)\n",
    "    return(newMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11766d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dip_nodup = pd.concat(listOfDF)\n",
    "#metrics_dip_nodup = newMetricsDF(dictEntries_d)\n",
    "metrics_dip_nodup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get all values that would be \"different\"\n",
    "def getDiffSubset(metrics):\n",
    "    progPairDF = metrics.copy()\n",
    "    sub2 = progPairDF[(progPairDF[\"p1_num_AT\"] > 1) | (progPairDF[\"p2_num_AT\"] > 1)]\n",
    "    print(sub2.shape)\n",
    "    sub3 = progPairDF[(progPairDF[\"p1_num_AT\"] == 0) & (progPairDF[\"p2_num_AT\"] == 1)]\n",
    "    #print(sub3)\n",
    "    print(sub3.shape)\n",
    "    sub4 = progPairDF[(progPairDF[\"p1_num_AT\"] == 1) & (progPairDF[\"p2_num_AT\"] == 0)]\n",
    "    #print(sub4)\n",
    "    print(sub4.shape)\n",
    "        \n",
    "    fulldiffAT = pd.concat([sub2, sub3, sub4])\n",
    "    \n",
    "    metrics_columns = list(metrics.columns)\n",
    "    diffDF = pd.DataFrame(diffList, columns = metrics_columns)\n",
    "    \n",
    "    return(diffDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dip = getSummaryNumbers(metrics_dip_nodup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66914c",
   "metadata": {},
   "source": [
    "# To correct for metrics (finding averages, then later adding to a new overall metrics table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04101dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 2: creating two dictionaries of dictionaries \n",
    "# dictionary of dictionaries\n",
    "# dictionary 1 = program 1 and program 2 as keys, gene and all other info as values\n",
    "# dictionary 2 = within each program 1 and program 2\n",
    "# groups of arabidopsis genes (the union of p1 and p2) as keys, all other info as values (in a list)\n",
    "\n",
    "#output_file = main_path + \"/comparison/240212_diploid/dictionarySets_diploid_240221_3.txt\"\n",
    "#file_to_write = open(output_file, \"a+\")\n",
    "def createDictionaries(subset):\n",
    "    programPairsSame = {}\n",
    "    programPairsDiff = {}\n",
    "    countSameList = {}\n",
    "    countDiffList = {}\n",
    "    for index, row in subset.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        #file_to_write.write(str(key1))\n",
    "        ATgene = row[1]\n",
    "        p1_num = row[-4]\n",
    "        p2_num = row[-2]\n",
    "        p1_AT = row[-3]\n",
    "        p2_AT = row[-1]\n",
    "        #file_to_write.write(str(p1_num) + \",\" + str(p2_num)+\"\\n\")\n",
    "        if p1_num == 0 and p2_num >= 1:\n",
    "            ATunion = p2_AT.split(\";\")\n",
    "            ATunion.sort()\n",
    "            \n",
    "            if key1 not in countDiffList:\n",
    "                countDiffList[key1] = [ATgene]\n",
    "            else:\n",
    "                countDiffList[key1].append(ATgene)\n",
    "                \n",
    "            if key1 not in programPairsDiff:\n",
    "                programPairsDiff[key1] = [set(ATunion)]\n",
    "                #file_to_write.write(\"1a: \" + ATgene + \"\\n\")\n",
    "            else:\n",
    "                count = 0\n",
    "                for gene in ATunion:\n",
    "                    for geneSet in programPairsDiff[key1]:\n",
    "                        if gene in geneSet:\n",
    "                            count = count + 1\n",
    "                            ind = programPairsDiff[key1].index(geneSet)\n",
    "                            \n",
    "                if count == 0:\n",
    "                    programPairsDiff[key1].append(set(ATunion))\n",
    "                else: \n",
    "                    programPairsDiff[key1][ind].update(ATunion)\n",
    "                    #file_to_write.write(\"1c: \"+ ATgene + \"\\n\")\n",
    "                \n",
    "        elif p1_num >= 1 and p2_num == 0:\n",
    "            ATunion = p1_AT.split(\",\")\n",
    "            ATunion.sort()\n",
    "            \n",
    "            if key1 not in countDiffList:\n",
    "                countDiffList[key1] = [ATgene]\n",
    "            else:\n",
    "                 countDiffList[key1].append(ATgene)\n",
    "                    \n",
    "            if key1 not in programPairsDiff:\n",
    "                programPairsDiff[key1] = [set(ATunion)]\n",
    "                #file_to_write.write(\"2a: \"+ ATgene + \"\\n\")\n",
    "            else:\n",
    "                count = 0\n",
    "                for gene in ATunion:\n",
    "                    for geneSet in programPairsDiff[key1]:\n",
    "                        if gene in geneSet:\n",
    "                            count = count + 1\n",
    "                            ind = programPairsDiff[key1].index(geneSet)\n",
    "                            \n",
    "                if count == 0:\n",
    "                    programPairsDiff[key1].append(set(ATunion))\n",
    "                else: \n",
    "                    programPairsDiff[key1][ind].update(ATunion)\n",
    "                    #file_to_write.write(\"2c: \"+ ATgene + \"\\n\")\n",
    "                \n",
    "        elif (p1_num > 1) or (p2_num > 1):\n",
    "            p1List = p1_AT.split(\",\") \n",
    "            p1List.sort()\n",
    "            p2List = p2_AT.split(\";\")\n",
    "            p2List.sort()\n",
    "            if p1List == p2List:\n",
    "                ATsame = list(set(p1List + p2List))\n",
    "                ATsame.sort()\n",
    "                \n",
    "                if key1 not in countSameList: \n",
    "                    countSameList[key1] = [ATgene] \n",
    "                else:\n",
    "                    countSameList[key1].append(ATgene)\n",
    "                \n",
    "                if key1 not in programPairsSame:\n",
    "                    programPairsSame[key1] = [set(ATsame)]\n",
    "                    #file_to_write.write(\"3a: \"+ ATgene + \"\\n\")\n",
    "                else:\n",
    "                    programPairsSame[key1].append(set(ATsame))\n",
    "                    #file_to_write.write(\"3b: \"+ ATgene+ \"\\n\")\n",
    "                        \n",
    "            else:\n",
    "                ATunion = list(set(p1List + p2List))\n",
    "                ATunion.sort()\n",
    "                \n",
    "                if key1 not in countDiffList:\n",
    "                    countDiffList[key1] = [ATgene]\n",
    "                else:\n",
    "                    countDiffList[key1].append(ATgene)\n",
    "                    \n",
    "                if key1 not in programPairsDiff:\n",
    "                    programPairsDiff[key1] = [set(ATunion)]\n",
    "                    #file_to_write.write(\"4a: \"+ ATgene+ \"\\n\")\n",
    "                else:\n",
    "                    count = 0\n",
    "                    for gene in ATunion:\n",
    "                        for geneSet in programPairsDiff[key1]:\n",
    "                            if gene in geneSet:\n",
    "                                count = count + 1\n",
    "                                ind = programPairsDiff[key1].index(geneSet)\n",
    "                    \n",
    "                    if count == 0:\n",
    "                        programPairsDiff[key1].append(set(ATunion))\n",
    "                    else: \n",
    "                        programPairsDiff[key1][ind].update(ATunion)\n",
    "                            #file_to_write.write(\"4c: \"+ ATgene+ \"\\n\")\n",
    "    \n",
    "    return(programPairsSame, programPairsDiff, countSameList, countDiffList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1355ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"create Dictionary\")\n",
    "sameATnum_d, diffATnum_d, countSame_d, countDiff_d = createDictionaries(metrics_dip_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842486cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in countDiff_d.items():\n",
    "    print(key)\n",
    "    print(len(item))\n",
    "    print(len(set(item)))\n",
    "    uniqueList = []\n",
    "    dupList = []\n",
    "    for gene in item:\n",
    "        if gene not in uniqueList:\n",
    "            uniqueList.append(gene)\n",
    "        else: \n",
    "            dupList.append(gene)\n",
    "    print(dupList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef61824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkNumGenes(dictionary):\n",
    "    for key, item in dictionary.items():\n",
    "        print(key)\n",
    "        print(len(item))\n",
    "        geneList =[]\n",
    "        for geneSet in item:\n",
    "            for gene3 in geneSet:\n",
    "                geneList.append(gene3)\n",
    "                \n",
    "        print(len(geneList))\n",
    "        print(len(set(geneList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74658398",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkNumGenes(diffATnum_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6dfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 3: checking the genes\n",
    "def checkGenesIncluded(dictionary1, dictionary2):\n",
    "    extraGenes = {}\n",
    "    for key, item in dictionary1.items():\n",
    "        print(key)\n",
    "        print(len(item))\n",
    "        geneList =[]\n",
    "        for geneSet in item:\n",
    "            for gene in geneSet:\n",
    "                geneList.append(gene)\n",
    "        print(len(geneList))\n",
    "        print(len(set(geneList)))\n",
    "    \n",
    "        genesNotInKey = set()\n",
    "        for key2, item2 in dictionary2.items():            \n",
    "            if key2 == key:\n",
    "                print(key2)\n",
    "                print(len(item))\n",
    "                for gene2 in geneList:\n",
    "                    if gene2 not in item2:\n",
    "                        genesNotInKey.add(gene2)\n",
    "        \n",
    "        print(len(genesNotInKey))\n",
    "        print(genesNotInKey)\n",
    "        \n",
    "        if len(genesNotInKey) > 0:\n",
    "            if key not in extraGenes:\n",
    "                extraGenes[key] = genesNotInKey\n",
    "                \n",
    "    return(extraGenes)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraBR_d = checkGenesIncluded(diffATnum_d, countDiff_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extraBR_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 4: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# iteration/comparison among the \"AT groups\" to see if there are any duplicate genes between them\n",
    "# stops only when only one final \"AT group\" to add to the list\n",
    "\n",
    "def removeDup_newSet(testList):\n",
    "    atgenes3 = []\n",
    "    for at_tuple in testList:\n",
    "        for tup in at_tuple:\n",
    "            atgenes3.append(tup)\n",
    "\n",
    "    #print(len(atgenes3))\n",
    "    test_copy = testList.copy()\n",
    "\n",
    "    newTupleList = testList\n",
    "\n",
    "    while len(atgenes3) != len(set(atgenes3)):\n",
    "        atgenes = []\n",
    "        #print(atgenes)\n",
    "        for i in range(len(newTupleList)):\n",
    "            for j in range(len(newTupleList)-1):\n",
    "                atgroup1 = newTupleList[i]\n",
    "                atgroup2 = newTupleList[j+1]\n",
    "                if atgroup1 != atgroup2:\n",
    "                    if len(set(atgroup1).intersection(set(atgroup2))) > 0:\n",
    "                        #print(\"at1\")\n",
    "                        #print(atgroup1)\n",
    "                        #print(\"at2\")\n",
    "                        #print(atgroup2)\n",
    "                        #print(atgroup1.intersection(atgroup2))\n",
    "                        keyunion = list(set(atgroup1).union(set(atgroup2)))\n",
    "                        keyunion.sort()\n",
    "                        #print(keyunion)\n",
    "                        if set(atgroup1) in test_copy:\n",
    "                            test_copy.remove(set(atgroup1))\n",
    "                        if set(atgroup2) in test_copy:\n",
    "                            test_copy.remove(set(atgroup2)) \n",
    "                        if set(keyunion) not in test_copy:\n",
    "                            test_copy.append(set(keyunion))\n",
    "                        \n",
    "                        atgenes.append(tuple(keyunion))\n",
    "                     \n",
    "                            \n",
    "        atgenes_nodup = set(atgenes)\n",
    "        #print(atgenes_nodup)\n",
    "        \n",
    "        atgenes3 = []\n",
    "        for at_tuple in atgenes_nodup:\n",
    "            for tup in at_tuple:\n",
    "                atgenes3.append(tup)\n",
    "\n",
    "        newTupleList = list(atgenes_nodup)\n",
    "\n",
    "        #print(\"lengthTuple:\")\n",
    "        print(len(atgenes3))\n",
    "        print(len(set(atgenes3)))\n",
    "    \n",
    "    print(len(testList))\n",
    "    print(len(test_copy))\n",
    "    return(test_copy)\n",
    "\n",
    "# function 5: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# removeDup_newSet function is found in this function\n",
    "# updating the keys for each program pair\n",
    "\n",
    "def updateKeys(dictionary):\n",
    "    newDict = {}\n",
    "\n",
    "    for programKey, keyList in dictionary.items():\n",
    "        print(programKey)\n",
    "        #print(keySet)\n",
    "        geneList =[]\n",
    "        for tup in keyList:\n",
    "            for gene in tup:\n",
    "                geneList.append(gene)\n",
    "        print(len(geneList))\n",
    "        print(len(set(geneList)))\n",
    "        \n",
    "        if len(geneList) == len(set(geneList)):\n",
    "            newDict[programKey] = keyList\n",
    "        else:\n",
    "            newKeyList = removeDup_newSet(keyList)\n",
    "            #print(newKeySet)\n",
    "            newDict[programKey] = newKeyList\n",
    "    return(newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b641fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "noDupGeneKey = updateKeys(diffATnum_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5197df",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkNumGenes(noDupGeneKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de157772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 6: for both the \"same\" and \"diff\" groups\n",
    "# create a new dictionary with the new keys, especially the updated ones for the \"diff\" set\n",
    "\n",
    "def createNewDictionary(dictionary):\n",
    "    newDictionary = {}\n",
    "    for programPair, atKeySet in dictionary.items():\n",
    "        if programPair not in newDictionary:\n",
    "            newDictionary[programPair] = {}\n",
    "            for atKey in atKeySet:\n",
    "                newATkey = list(atKey)\n",
    "                newATkey.sort()\n",
    "                newATkey = tuple(newATkey)\n",
    "                if newATkey not in newDictionary[programPair]:\n",
    "                    newDictionary[programPair][newATkey] = []\n",
    "    return(newDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 7: add values to the dictionary of dictionaries\n",
    "# values are individual rows\n",
    "# if the AT gene is found in the AT key, which is the union of AT genes found between the two orthogroups\n",
    "\n",
    "def addValuesToDictionaries_Diff(subset, dictionary, geneDict):    \n",
    "    for index, row in subset.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        gene = row[1]\n",
    "        if key1 in geneDict:\n",
    "            extraGenes = geneDict[key1]\n",
    "            for ATkey, items in dictionary[key1].items():\n",
    "                #print(ATkey)\n",
    "                if gene in ATkey:\n",
    "                    #print(gene)\n",
    "                    if gene not in extraGenes:\n",
    "                        dictionary[key1][ATkey].append(row.tolist())\n",
    "        else:\n",
    "            for ATkey, items in dictionary[key1].items():\n",
    "                #print(ATkey)\n",
    "                if gene in ATkey:\n",
    "                    dictionary[key1][ATkey].append(row.tolist())\n",
    "                \n",
    "    return(dictionary) \n",
    "\n",
    "def addValuesToDictionaries_Same(subset, dictionary):    \n",
    "    for index, row in subset.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        gene = row[1]\n",
    "        for ATkey, items in dictionary[key1].items():\n",
    "            #print(ATkey)\n",
    "            if gene in ATkey:\n",
    "                #print(gene)\n",
    "                dictionary[key1][ATkey].append(row.tolist())\n",
    "    return(dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 8: finding the average metric values for each union of AT genes\n",
    "# taking the average for all of the metrics\n",
    "# however, hard to find the \"average\" for the number of AT genes in p1 and p2 and the AT gene compositions\n",
    "# so taking the values from the first gene in the list\n",
    "\n",
    "def newAvgList(programPairs):\n",
    "    programKeys = programPairs.keys()\n",
    "    newAvgValues = []\n",
    "    programPairCount = []\n",
    "    for pairKey in programKeys:\n",
    "        #print(pairKey)\n",
    "        countList = []\n",
    "        for ATkey, items in programPairs[pairKey].items():\n",
    "            geneOG = ATkey\n",
    "            #print(ATkey)\n",
    "            program1 = items[0][2]\n",
    "            program2 = items[0][3]\n",
    "            RSavg = sum(float(x[4]) for x in items)/len(items)\n",
    "            ARSavg = sum(float(x[5]) for x in items)/len(items)\n",
    "            intersectionAvg = sum(float(x[6]) for x in items)/len(items)\n",
    "            unionAvg = sum(float(x[7]) for x in items)/len(items)\n",
    "            JIavg = sum(float(x[8]) for x in items)/len(items)\n",
    "            p1_num = items[0][9]\n",
    "            p1_ATlist = items[0][10]\n",
    "            p2_num = items[0][11]\n",
    "            p2_ATlist = items[0][12]\n",
    "            #print([geneOG, program1, program2, RSavg, ARSavg, intersectionAvg, unionAvg,JIavg,p1_num,p1_ATlist,p2_num,p2_ATlist])\n",
    "            newAvgValues.append([geneOG, program1, program2, RSavg, ARSavg, intersectionAvg, unionAvg,JIavg,p1_num,p1_ATlist,p2_num,p2_ATlist])\n",
    "            countList.append(len(ATkey))\n",
    "            \n",
    "        finalCount = sum(countList) \n",
    "        print(finalCount)\n",
    "        programPairCount.append([pairKey, finalCount])\n",
    "        \n",
    "    return(newAvgValues, programPairCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce24169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remainder code for OG with different AT genes\n",
    "print(\"create new dictionary of dictionaries with new AT keys\")\n",
    "newProgramPairsDiff_d = createNewDictionary(noDupGeneKey)\n",
    "print(\"add values\")\n",
    "diffATvalue = addValuesToDictionaries_Diff(metrics_dip_nodup, newProgramPairsDiff_d, extraBR_d)\n",
    "print(\"calc new avg\")\n",
    "diffOGList_d, oriATnum_diff_d = newAvgList(diffATvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for OG with same AT numbers/gene composition\n",
    "print(\"for same AT numbers\")\n",
    "print('check new gene numbers')\n",
    "checkNumGenes(sameATnum_d)\n",
    "print(\" create new dicitonary of dictionaries with new AT keys\")\n",
    "newProgramPairsSame_d = createNewDictionary(sameATnum_d)\n",
    "print(\"add values\")\n",
    "sameATvalue_d = addValuesToDictionaries_Same(metrics_dip_nodup, newProgramPairsSame_d)\n",
    "print(\"calc new avg\")\n",
    "sameOGList_d, oriATnum_same_d = newAvgList(sameATvalue_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dacf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes for both datasets\n",
    "columnNames = [\"gene\",\"program1\",\"program2\",\"RS\",\"ARS\",\"intersection\",\"union\",\"Jaccard\",\"p1_num_AT\",\n",
    "                   \"p1_AT_genes\",\"p2_num_AT\",\"p2_AT_genes\"]\n",
    "\n",
    "sameOGdf_d = pd.DataFrame(sameOGList_d, columns=columnNames)\n",
    "diffOGdf_d = pd.DataFrame(diffOGList_d, columns=columnNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae5484",
   "metadata": {},
   "source": [
    "## Summary of number of orthogroups of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 1: get the initial summary numbers from the original metrics table\n",
    "def getSummaryNumbers(metrics):\n",
    "    programPairs= {}\n",
    "    for index, row in metrics.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        if key1 not in programPairs:\n",
    "            programPairs[key1] = []\n",
    "            programPairs[key1].append(row.tolist())\n",
    "        else:\n",
    "            programPairs[key1].append(row.tolist())\n",
    "            \n",
    "    sumList = []\n",
    "    for pairKey, metricRow in programPairs.items():\n",
    "        print(pairKey)\n",
    "        columnNames = list(metrics.columns)\n",
    "        progPairDF = pd.DataFrame(metricRow, columns = columnNames)\n",
    "        print(progPairDF.shape)\n",
    "        #print(progPairDF)\n",
    "        sub1 = progPairDF[(progPairDF[\"p1_num_AT\"] == 1) & (progPairDF[\"p2_num_AT\"] == 1)]\n",
    "        sub1 = sub1.drop_duplicates(subset=sub1.columns.difference(['Unnamed: 0']))\n",
    "        print(sub1.shape)\n",
    "        sub2 = progPairDF[(progPairDF[\"p1_num_AT\"] > 1) | (progPairDF[\"p2_num_AT\"] > 1)]\n",
    "        sub2 = sub2.drop_duplicates(subset=sub2.columns.difference(['Unnamed: 0']))\n",
    "        print(sub2.shape)\n",
    "        sub3 = progPairDF[(progPairDF[\"p1_num_AT\"] == 0) & (progPairDF[\"p2_num_AT\"] == 1)]\n",
    "        sub3 = sub3.drop_duplicates(subset=sub3.columns.difference(['Unnamed: 0']))\n",
    "        #print(sub3)\n",
    "        print(sub3.shape)\n",
    "        sub4 = progPairDF[(progPairDF[\"p1_num_AT\"] == 1) & (progPairDF[\"p2_num_AT\"] == 0)]\n",
    "        sub4 = sub4.drop_duplicates(subset=sub4.columns.difference(['Unnamed: 0']))\n",
    "        #print(sub4)\n",
    "        print(sub4.shape)\n",
    "        \n",
    "        fulldiffAT = sub2.shape[0] + sub3.shape[0] + sub4.shape[0]\n",
    "        \n",
    "        sumList.append([pairKey, progPairDF.shape[0], sub1.shape[0], fulldiffAT])\n",
    "    \n",
    "    summaryDF = pd.DataFrame(sumList, columns = [\"programPair\",\"All\",\"oneAT\",\"diffAT\"])\n",
    "    summaryDF[\"Total\"] = summaryDF[\"oneAT\"] + summaryDF[\"diffAT\"]\n",
    "    summaryDF[\"PropOne\"] = summaryDF[\"oneAT\"]/summaryDF[\"Total\"]\n",
    "    \n",
    "    return(summaryDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 2: counting the number of orthogroups for comparison from the updated list\n",
    "\n",
    "def countrowsNewDF(dataframe):\n",
    "    programPairs= {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        key1 = (row[1], row[2])\n",
    "        if key1 not in programPairs:\n",
    "            programPairs[key1] = []\n",
    "            programPairs[key1].append(row.tolist())\n",
    "        else:\n",
    "            programPairs[key1].append(row.tolist())\n",
    "    \n",
    "    countList = []\n",
    "    for pairKey, metricRow in programPairs.items():\n",
    "        print(pairKey)\n",
    "        columnNames = list(dataframe.columns)\n",
    "        progPairDF = pd.DataFrame(metricRow, columns = columnNames)\n",
    "        progPairDF_nodup = progPairDF.drop_duplicates(subset=progPairDF.columns.difference(['Unnamed: 0']))\n",
    "        print(progPairDF.shape)\n",
    "        print(progPairDF_nodup.shape)\n",
    "        countList.append([pairKey,progPairDF_nodup.shape[0]])\n",
    "    \n",
    "    return(countList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 3: combine all the outputs into a summary dataframe\n",
    "\n",
    "def combineDF(metricsDF, ori_cts1_s, ori_cts1_d, newSameDF, newDiffDF):\n",
    "    initialSummary = getSummaryNumbers(metricsDF)\n",
    "    \n",
    "    oriCountSame_DF = pd.DataFrame(ori_cts1_s, columns=[\"programPair\",\"oriATgenes_same\"])\n",
    "    oriCountDiff_DF = pd.DataFrame(ori_cts1_d, columns=[\"programPair\",\"oriATgenes_diff\"])\n",
    "    \n",
    "    list_same = countrowsNewDF(newSameDF)\n",
    "    list_diff = countrowsNewDF(newDiffDF)\n",
    "    \n",
    "    newCountSame_DF = pd.DataFrame(list_same, columns=[\"programPair\",\"combAvg_same\"])\n",
    "    newCountDiff_DF = pd.DataFrame(list_diff, columns=[\"programPair\",\"combAvg_diff\"])\n",
    "    \n",
    "    listOfDF = [initialSummary, oriCountSame_DF, newCountSame_DF, oriCountDiff_DF, newCountDiff_DF]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['programPair']), listOfDF)\n",
    "    \n",
    "    df_merged[\"newTotalOG\"] = df_merged[\"oneAT\"] + df_merged[\"combAvg_same\"] + df_merged[\"combAvg_diff\"]\n",
    "    df_merged[\"oriTotal\"] = df_merged[\"oriATgenes_same\"] + df_merged[\"oriATgenes_diff\"] \n",
    "    \n",
    "    return(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to create summary dataframe\n",
    "diploid_sum = combineDF(metrics_dip_nodup, oriATnum_same_d, oriATnum_diff_d, sameOGdf_d, diffOGdf_d)\n",
    "summaryOutput_d = main_path + \"/comparison/240212_diploid/summary_diploid_240221.csv\"\n",
    "diploid_sum.to_csv(summaryOutput_d, index = False)\n",
    "\n",
    "# Creating the final updated metrics table for making heatmaps\n",
    "oneSubset_d = metrics_dip_nodup[(metrics_dip_nodup[\"p1_num_AT\"]== 1) & (metrics_dip_nodup[\"p2_num_AT\"] == 1)]\n",
    "oneSubset_d = oneSubset_d.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(oneSubset_d.shape)\n",
    "print(\"concatenate dataframes\")\n",
    "metrics_dfs_d = [oneSubset_d, sameOGdf_d, diffOGdf_d]\n",
    "metrics_merged_d = pd.concat(metrics_dfs_d)\n",
    "print(metrics_merged_d.shape)\n",
    "print(\"drop duplicates\")\n",
    "nodup_merged_d = metrics_merged_d.drop_duplicates()\n",
    "print(nodup_merged_d.shape)\n",
    "newMetricsNoDup_out_d = main_path + \"/comparison/240212_diploid/diploid_newMetrics_noDup_240221.csv\"\n",
    "nodup_merged_d.to_csv(newMetricsNoDup_out_d, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6bab4",
   "metadata": {},
   "source": [
    "## Generate new metrics dataframe with corrected orthogroup comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ef997",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# START HERE #\n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3b341",
   "metadata": {},
   "source": [
    "### DIPLOID set of functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a24ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general code, but first couple of lines () - use the above code/boxes to track or\n",
    "# make corrections/adjustments when errors popup\n",
    "main_path = r\"/path_to_files\"\n",
    "\n",
    "# read in files\n",
    "print(\"read file\")\n",
    "dip_file = main_path + \"/comparison/240212_diploid/diploid_pairwiseMetrics_240212.csv\"\n",
    "metrics_dip = pd.read_csv(dip_file)\n",
    "metrics_dip.replace('na', np.nan, inplace=True)\n",
    "\n",
    "subset_d = metrics_dip\n",
    "print(\"remove duplicate entries of BR genes\")\n",
    "dictEntries_d, uniqueList_d, duplicateDict_d = removeDuplicateEntries(subset_d)\n",
    "print(\"concatenate rows for new metrics table\")\n",
    "metrics_dip_nodup = newMetricsDF(dictEntries_d)\n",
    "print(\"create Dictionary\")\n",
    "sameATnum_d, diffATnum_d, countSame_d, countDiff_d = createDictionaries(metrics_dip_nodup)\n",
    "\n",
    "\n",
    "# for OG with different AT numbers/gene composition\n",
    "print(\"for diff AT numbers\")\n",
    "print(\"get dictionary of extra genes for BR to not include later\")\n",
    "extraBR_d = checkGenesIncluded(diffATnum_d, countDiff_d)\n",
    "print(\"check number of genes\")\n",
    "checkNumGenes(diffATnum_d)\n",
    "print(\"iterative method to get equal genes in dictionary keys of AT genes\")\n",
    "noDupGeneKey = updateKeys(diffATnum_d)\n",
    "print(\"check number of genes again\")\n",
    "checkNumGenes(noDupGeneKey)\n",
    "print(\"create new dictionary of dictionaries with new AT keys\")\n",
    "newProgramPairsDiff_d = createNewDictionary(noDupGeneKey)\n",
    "print(\"add values\")\n",
    "diffATvalue_d = addValuesToDictionaries_Diff(metrics_dip_nodup, newProgramPairsDiff_d, extraBR_d)\n",
    "print(\"calc new avg\")\n",
    "diffOGList_d, oriATnum_diff_d = newAvgList(diffATvalue_d)\n",
    "\n",
    "# for OG with same AT numbers/gene composition\n",
    "print(\"for same AT numbers\")\n",
    "print('check new gene numbers')\n",
    "checkNumGenes(sameATnum_d)\n",
    "print(\" create new dicitonary of dictionaries with new AT keys\")\n",
    "newProgramPairsSame_d = createNewDictionary(sameATnum_d)\n",
    "print(\"add values\")\n",
    "sameATvalue_d = addValuesToDictionaries(metrics_dip_nodup, newProgramPairsSame_d)\n",
    "print(\"calc new avg\")\n",
    "sameOGList_d, oriATnum_same_d = newAvgList(sameATvalue_d)\n",
    "\n",
    "create dataframes for both datasets\n",
    "columnNames = [\"gene\",\"program1\",\"program2\",\"RS\",\"ARS\",\"intersection\",\"union\",\"Jaccard\",\"p1_num_AT\",\n",
    "                   \"p1_AT_genes\",\"p2_num_AT\",\"p2_AT_genes\"]\n",
    "\n",
    "sameOGdf_d = pd.DataFrame(sameOGList_d, columns=columnNames)\n",
    "diffOGdf_d = pd.DataFrame(diffOGList_d, columns=columnNames)\n",
    "\n",
    "# call function to create summary dataframe\n",
    "diploid_sum = combineDF(metrics_dip_nodup, oriATnum_same_d, oriATnum_diff_d, sameOGdf_d, diffOGdf_d)\n",
    "summaryOutput_d = main_path + \"/comparison/240212_diploid/summary_diploid_240221.csv\"\n",
    "diploid_sum.to_csv(summaryOutput_d, index = False)\n",
    "\n",
    "# Creating the final updated metrics table for making heatmaps\n",
    "oneSubset_d = metrics_dip[(metrics_dip[\"p1_num_AT\"]== 1) & (metrics_dip[\"p2_num_AT\"] == 1)]\n",
    "oneSubset_d = oneSubset_d.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(oneSubset_d.shape)\n",
    "print(\"concatenate dataframes\")\n",
    "metrics_dfs_d = [oneSubset_d, sameOGdf_d, diffOGdf_d]\n",
    "metrics_merged_d = pd.concat(metrics_dfs_d)\n",
    "print(nodup_merged_d.shape)\n",
    "print(\"drop duplicates\")\n",
    "nodup_merged_d = metrics_merged_d.drop_duplicates()\n",
    "print(nodup_merged_d.shape)\n",
    "newMetricsNoDup_out_d = main_path + \"/comparison/240212_diploid/diploid_newMetrics_noDup_240221.csv\"\n",
    "nodup_merged_d.to_csv(newMetricsNoDup_out_d, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd30989",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkNumGenes(sameATnum_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946db940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in countDiff_d.items():\n",
    "    print(key)\n",
    "    print(len(item))\n",
    "    print(len(set(item)))\n",
    "    uniqueList = []\n",
    "    dupList = []\n",
    "    for gene in item:\n",
    "        if gene not in uniqueList:\n",
    "            uniqueList.append(gene)\n",
    "        else: \n",
    "            dupList.append(gene)\n",
    "    print(dupList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b63882",
   "metadata": {},
   "source": [
    "### for the diploid+higher ploidy \"FULL set of functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = r\"/path_to_files\"\n",
    "\n",
    "# read in files\n",
    "print(\"read file\")\n",
    "full_file = main_path + \"/comparison/240209_full/full_pairwiseMetrics_240209.csv\"\n",
    "metrics_full = pd.read_csv(full_file)\n",
    "metrics_full.replace('na', np.nan, inplace=True)\n",
    "\n",
    "subset_f = metrics_full\n",
    "print(\"remove duplicate entries of BR genes\")\n",
    "dictEntries_f, uniqueList_f, duplicateDict_f = removeDuplicateEntries(subset_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"concatenate rows for new metrics table\")\n",
    "metrics_full_nodup = newMetricsDF(dictEntries_f)\n",
    "print(\"create Dictionary\")\n",
    "sameATnum_f, diffATnum_f, countSame_f, countDiff_f = createDictionaries(metrics_full_nodup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fcb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for OG with different AT numbers/gene composition\n",
    "print(\"for diff AT numbers\")\n",
    "print(\"get dictionary of extra genes for BR to not include later\")\n",
    "extraBR_f = checkGenesIncluded(diffATnum_f, countDiff_f)\n",
    "print(\"check number of genes\")\n",
    "checkNumGenes(diffATnum_f)\n",
    "print(\"iterative method to get equal genes in dictionary keys of AT genes\")\n",
    "noDupGeneKey_f = updateKeys(diffATnum_f)\n",
    "print(\"check number of genes again\")\n",
    "checkNumGenes(noDupGeneKey_f)\n",
    "print(\"create new dictionary of dictionaries with new AT keys\")\n",
    "newProgramPairsDiff_f = createNewDictionary(noDupGeneKey_f)\n",
    "print(\"add values\")\n",
    "diffATvalue_f = addValuesToDictionaries_Diff(metrics_full_nodup, newProgramPairsDiff_f, extraBR_f)\n",
    "print(\"calc new avg\")\n",
    "diffOGList_f, oriATnum_diff_f = newAvgList(diffATvalue_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for OG with same AT numbers/gene composition\n",
    "print(\"for same AT numbers\")\n",
    "print('check new gene numbers')\n",
    "checkNumGenes(sameATnum_f)\n",
    "print(\"create new dicitonary of dictionaries with new AT keys\")\n",
    "newProgramPairsSame_f = createNewDictionary(sameATnum_f)\n",
    "print(\"add values\")\n",
    "sameATvalue_f = addValuesToDictionaries_Same(metrics_full_nodup, newProgramPairsSame_f)\n",
    "print(\"calc new avg\")\n",
    "sameOGList_f, oriATnum_same_f = newAvgList(sameATvalue_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f855f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes for both datasets\n",
    "columnNames = [\"gene\",\"program1\",\"program2\",\"RS\",\"ARS\",\"intersection\",\"union\",\"Jaccard\",\"p1_num_AT\",\n",
    "                   \"p1_AT_genes\",\"p2_num_AT\",\"p2_AT_genes\"]\n",
    "\n",
    "sameOGdf_f = pd.DataFrame(sameOGList_f, columns=columnNames)\n",
    "diffOGdf_f = pd.DataFrame(diffOGList_f, columns=columnNames)\n",
    "\n",
    "# call function to create summary dataframe\n",
    "full_sum = combineDF(metrics_full_nodup, oriATnum_same_f, oriATnum_diff_f, sameOGdf_f, diffOGdf_f)\n",
    "summaryOutput_f = main_path + \"/comparison/240209_full/summary_full_240221.csv\"\n",
    "full_sum.to_csv(summaryOutput_f, index = False)\n",
    "\n",
    "# Creating the final updated metrics table for making heatmaps\n",
    "oneSubset_f = metrics_full_nodup[(metrics_full_nodup[\"p1_num_AT\"]== 1) & (metrics_full_nodup[\"p2_num_AT\"] == 1)]\n",
    "oneSubset_f = oneSubset_f.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(oneSubset_f.shape)\n",
    "print(\"concatenate dataframes\")\n",
    "metrics_dfs_f = [oneSubset_f, sameOGdf_f, diffOGdf_f]\n",
    "metrics_merged_f = pd.concat(metrics_dfs_f)\n",
    "print(metrics_merged_f.shape)\n",
    "print(\"drop duplicates\")\n",
    "nodup_merged_f = metrics_merged_f.drop_duplicates()\n",
    "print(nodup_merged_f.shape)\n",
    "newMetricsNoDup_out_f = main_path + \"/comparison/240209_full/full_newMetrics_noDup_240221.csv\"\n",
    "nodup_merged_f.to_csv(newMetricsNoDup_out_f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f564bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "newMetricsNoDup_out_f = main_path + \"/comparison/240209_full/full_newMetrics_noDup_240221.csv\"\n",
    "nodup_merged_f.to_csv(newMetricsNoDup_out_f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418b16c",
   "metadata": {},
   "source": [
    "## Entire script put into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a335c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "######################\n",
    "# FUNCTIONS - PART 1 #\n",
    "######################\n",
    "\n",
    "# function 1: creating two dictionaries of dictionaries \n",
    "# dictionary of dictionaries\n",
    "# dictionary 1 = program 1 and program 2 as keys, gene and all other info as values\n",
    "# dictionary 2 = within each program 1 and program 2\n",
    "# groups of arabidopsis genes (the union of p1 and p2) as keys, all other info as values (in a list)\n",
    "\n",
    "def createDictionaries(subset):\n",
    "    programPairsSame = {}\n",
    "    programPairsDiff = {}\n",
    "    for index, row in subset.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        #print(key1)\n",
    "        p1_num = row[-4]\n",
    "        p2_num = row[-2]\n",
    "        p1_AT = row[-3]\n",
    "        p2_AT = row[-1]\n",
    "        #print(p1_num, p2_num)\n",
    "        if p1_num == 0 and p2_num >= 1:\n",
    "            ATunion = p2_AT.split(\";\")\n",
    "            ATunion.sort()\n",
    "\n",
    "            if key1 not in programPairsDiff:\n",
    "                programPairsDiff[key1] = set()\n",
    "                programPairsDiff[key1].add(tuple(ATunion))\n",
    "            else:\n",
    "                programPairsDiff[key1].add(tuple(ATunion))\n",
    "            \n",
    "        elif p2_num == 0 and p1_num >= 1:\n",
    "            ATunion = p1_AT.split(\",\")\n",
    "            ATunion.sort()\n",
    "\n",
    "            if key1 not in programPairsDiff:\n",
    "                programPairsDiff[key1] = set()\n",
    "                programPairsDiff[key1].add(tuple(ATunion))\n",
    "            else:\n",
    "                programPairsDiff[key1].add(tuple(ATunion))\n",
    "                \n",
    "        elif (p1_num > 1) or (p2_num > 1):\n",
    "            p1List = p1_AT.split(\",\") \n",
    "            p1List.sort()\n",
    "            p2List = p2_AT.split(\";\")\n",
    "            p2List.sort()\n",
    "            if p1List == p2List:\n",
    "                ATsame = list(set(p1_AT.split(\",\") + p2_AT.split(\";\")))\n",
    "                ATsame.sort()\n",
    "                if key1 not in programPairsSame:\n",
    "                    programPairsSame[key1] = set()\n",
    "                    programPairsSame[key1].add(tuple(ATsame)) \n",
    "                else:\n",
    "                    programPairsSame[key1].add(tuple(ATsame))\n",
    "                        \n",
    "            else:\n",
    "                ATunion = list(set(p1_AT.split(\",\") + p2_AT.split(\";\")))\n",
    "                ATunion.sort()\n",
    "                if key1 not in programPairsDiff:\n",
    "                    programPairsDiff[key1] = set()\n",
    "                    programPairsDiff[key1].add(tuple(ATunion))\n",
    "                else:\n",
    "                    programPairsDiff[key1].add(tuple(ATunion))\n",
    "                        \n",
    "    return(programPairsSame, programPairsDiff)\n",
    "\n",
    "# function 2: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# need to find the most inclusive group of AT genes, for the clusters with different number of AT\n",
    "# genes in the two orhtogroups\n",
    "\n",
    "def InclusiveATkey(dictionary):\n",
    "    \n",
    "    programKeys = dictionary.keys()\n",
    "    new_uniqueKeys_dict = {}\n",
    "    \n",
    "    for pairKey in programKeys:\n",
    "        uniqueKeys = {}\n",
    "        for atkey in dictionary[pairKey]:\n",
    "            #print(atkey)\n",
    "            for atgene in atkey:\n",
    "                if atgene not in uniqueKeys:\n",
    "                    uniqueKeys[atgene] = []\n",
    "                    uniqueKeys[atgene].append(atkey)\n",
    "                else: \n",
    "                    uniqueKeys[atgene].append(atkey)\n",
    "\n",
    "        newKeySet = set()\n",
    "        for atgene2, listOfATkeys in uniqueKeys.items():\n",
    "            maxATkey = max(atkey2 for atkey2 in listOfATkeys)\n",
    "            #print(maxATkey)\n",
    "            newKeySet.add(maxATkey)\n",
    "        \n",
    "        if pairKey not in new_uniqueKeys_dict:\n",
    "            new_uniqueKeys_dict[pairKey]=set()\n",
    "        \n",
    "            for uniqueATkey in newKeySet:\n",
    "                if uniqueATkey not in new_uniqueKeys_dict[pairKey]:\n",
    "                    #print(uniqueATkey)\n",
    "                    new_uniqueKeys_dict[pairKey].add(uniqueATkey)\n",
    "            \n",
    "    return(new_uniqueKeys_dict)\n",
    "\n",
    "# function 3: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# to check number of genes in the keys\n",
    "def checkNumGenes(dictionary):\n",
    "    for key, item in dictionary.items():\n",
    "        print(key)\n",
    "        print(len(item))\n",
    "        geneList =[]\n",
    "        for tup in item:\n",
    "            for gene in tup:\n",
    "                geneList.append(gene)\n",
    "                \n",
    "        print(len(geneList))\n",
    "        print(len(set(geneList)))\n",
    "        \n",
    "# function 4: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# iteration/comparison among the \"AT groups\" to see if there are any duplicate genes between them\n",
    "# stops only when only one final \"AT group\" to add to the list\n",
    "\n",
    "def removeDup_newSet(test):\n",
    "    atgenes3 = []\n",
    "    for at_tuple in test:\n",
    "        for tup in at_tuple:\n",
    "            atgenes3.append(tup)\n",
    "\n",
    "    #print(len(atgenes3))\n",
    "    test_copy = test.copy()\n",
    "\n",
    "    newTupleList = test\n",
    "\n",
    "    while len(atgenes3) != len(set(atgenes3)):\n",
    "        atgenes = []\n",
    "        for atgroup1 in newTupleList:\n",
    "            for atgroup2 in newTupleList:\n",
    "                if atgroup1 != atgroup2:\n",
    "                    if len(set(atgroup1).intersection(set(atgroup2))) > 0:\n",
    "                        #print(atgroup1)\n",
    "                        #print(atgroup2)\n",
    "                        #print(set(x).intersection(set(y)))\n",
    "                        keyunion = list(set(atgroup1).union(set(atgroup2)))\n",
    "                        keyunion.sort()\n",
    "                        #print(keyunion)\n",
    "                        test_copy.discard(atgroup1)\n",
    "                        test_copy.discard(atgroup2)\n",
    "                        atgenes.append(tuple(keyunion))\n",
    "                        test_copy.add(tuple(keyunion))\n",
    "\n",
    "        atgenes_nodup = set(atgenes)\n",
    "\n",
    "        atgenes3 = []\n",
    "        for at_tuple in atgenes_nodup:\n",
    "            for tup in at_tuple:\n",
    "                atgenes3.append(tup)\n",
    "\n",
    "        newTupleList = atgenes_nodup\n",
    "\n",
    "        #print(\"lengthTuple:\")\n",
    "        print(len(atgenes3))\n",
    "        print(len(set(atgenes3)))\n",
    "    \n",
    "    return(test_copy)\n",
    "\n",
    "# function 5: for only the scenario where the AT genes are not exactly the same between the two orthogroups\n",
    "# removeDup_newSet function is found in this function\n",
    "# updating the keys for each program pair\n",
    "\n",
    "def updateKeys(dictionary):\n",
    "    newDict = {}\n",
    "\n",
    "    for programKey, keySet in dictionary.items():\n",
    "        print(programKey)\n",
    "        #print(keySet)\n",
    "        geneList =[]\n",
    "        for tup in keySet:\n",
    "            for gene in tup:\n",
    "                geneList.append(gene)\n",
    "        print(len(geneList))\n",
    "        print(len(set(geneList)))\n",
    "        \n",
    "        if len(geneList) == len(set(geneList)):\n",
    "            newDict[programKey] = keySet\n",
    "        else:\n",
    "            newKeySet = removeDup_newSet(keySet)\n",
    "            #print(newKeySet)\n",
    "            newDict[programKey] = newKeySet\n",
    "    return(newDict)\n",
    "\n",
    "# function 6: for both the \"same\" and \"diff\" groups\n",
    "# create a new dictionary with the new keys, especially the updated ones for the \"diff\" set\n",
    "\n",
    "def createNewDictionary(dictionary):\n",
    "    newDictionary = {}\n",
    "    for programPair, atKeySet in dictionary.items():\n",
    "        if programPair not in newDictionary:\n",
    "            newDictionary[programPair] = {}\n",
    "            for atKey in atKeySet:\n",
    "                newDictionary[programPair][atKey] = []\n",
    "    return(newDictionary)\n",
    "\n",
    "# function 7: add values to the dictionary of dictionaries\n",
    "# values are individual rows\n",
    "# if the AT gene is found in the AT key, which is the union of AT genes found between the two orthogroups\n",
    "\n",
    "def addValuesToDictionaries(subset, dictionary):    \n",
    "    for index, row in subset.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        gene = row[1]\n",
    "        for ATkey, items in dictionary[key1].items():\n",
    "            #print(ATkey)\n",
    "            if gene in ATkey:\n",
    "                #print(gene)\n",
    "                #print(row.tolist())\n",
    "                dictionary[key1][ATkey].append(row.tolist())\n",
    "    return(dictionary) \n",
    "\n",
    "# function 8: finding the average metric values for each union of AT genes\n",
    "# taking the average for all of the metrics\n",
    "# however, hard to find the \"average\" for the number of AT genes in p1 and p2 and the AT gene compositions\n",
    "# so taking the values from the first gene in the list\n",
    "\n",
    "def newAvgList(programPairs):\n",
    "    programKeys = programPairs.keys()\n",
    "    newAvgValues = []\n",
    "    programPairCount = []\n",
    "    for pairKey in programKeys:\n",
    "        #print(pairKey)\n",
    "        countList = []\n",
    "        for ATkey, items in programPairs[pairKey].items():\n",
    "            geneOG = ATkey\n",
    "            #print(ATkey)\n",
    "            program1 = items[0][2]\n",
    "            program2 = items[0][3]\n",
    "            RSavg = sum(float(x[4]) for x in items)/len(items)\n",
    "            ARSavg = sum(float(x[5]) for x in items)/len(items)\n",
    "            intersectionAvg = sum(float(x[6]) for x in items)/len(items)\n",
    "            unionAvg = sum(float(x[7]) for x in items)/len(items)\n",
    "            JIavg = sum(float(x[8]) for x in items)/len(items)\n",
    "            p1_num = items[0][9]\n",
    "            p1_ATlist = items[0][10]\n",
    "            p2_num = items[0][11]\n",
    "            p2_ATlist = items[0][12]\n",
    "            #print([geneOG, program1, program2, RSavg, ARSavg, intersectionAvg, unionAvg,JIavg,p1_num,p1_ATlist,p2_num,p2_ATlist])\n",
    "            newAvgValues.append([geneOG, program1, program2, RSavg, ARSavg, intersectionAvg, unionAvg,JIavg,p1_num,p1_ATlist,p2_num,p2_ATlist])\n",
    "            countList.append(len(ATkey))\n",
    "            \n",
    "        finalCount = sum(countList) \n",
    "        print(finalCount)\n",
    "        programPairCount.append([pairKey, finalCount])\n",
    "        \n",
    "    return(newAvgValues, programPairCount)\n",
    "\n",
    "######################\n",
    "# FUNCTIONS - PART 2 #\n",
    "######################\n",
    "\n",
    "# functions for making summary dataframe\n",
    "\n",
    "# function 1: get the initial summary numbers from the original metrics table\n",
    "def getSummaryNumbers(metrics):\n",
    "    programPairs= {}\n",
    "    for index, row in metrics.iterrows():\n",
    "        key1 = (row[2], row[3])\n",
    "        if key1 not in programPairs:\n",
    "            programPairs[key1] = []\n",
    "            programPairs[key1].append(row.tolist())\n",
    "        else:\n",
    "            programPairs[key1].append(row.tolist())\n",
    "            \n",
    "    sumList = []\n",
    "    for pairKey, metricRow in programPairs.items():\n",
    "        print(pairKey)\n",
    "        columnNames = list(metrics.columns)\n",
    "        progPairDF = pd.DataFrame(metricRow, columns = columnNames)\n",
    "        print(progPairDF.shape)\n",
    "        #print(progPairDF)\n",
    "        sub1 = progPairDF[(progPairDF[\"p1_num_AT\"] == 1) & (progPairDF[\"p2_num_AT\"] == 1)]\n",
    "        print(sub1.shape)\n",
    "        sub2 = progPairDF[(progPairDF[\"p1_num_AT\"] > 1) | (progPairDF[\"p2_num_AT\"] > 1)]\n",
    "        print(sub2.shape)\n",
    "        sub3 = progPairDF[(progPairDF[\"p1_num_AT\"] == 0) & (progPairDF[\"p2_num_AT\"] == 1)]\n",
    "        #print(sub3)\n",
    "        print(sub3.shape)\n",
    "        sub4 = progPairDF[(progPairDF[\"p1_num_AT\"] == 1) & (progPairDF[\"p2_num_AT\"] == 0)]\n",
    "        #print(sub4)\n",
    "        print(sub4.shape)\n",
    "        \n",
    "        fulldiffAT = sub2.shape[0] + sub3.shape[0] + sub4.shape[0]\n",
    "        \n",
    "        sumList.append([pairKey, progPairDF.shape[0], sub1.shape[0], fulldiffAT])\n",
    "    \n",
    "    summaryDF = pd.DataFrame(sumList, columns = [\"programPair\",\"All\",\"oneAT\",\"diffAT\"])\n",
    "    summaryDF[\"Total\"] = summaryDF[\"oneAT\"] + summaryDF[\"diffAT\"]\n",
    "    summaryDF[\"PropOne\"] = summaryDF[\"oneAT\"]/summaryDF[\"Total\"]\n",
    "    \n",
    "    return(summaryDF)\n",
    "\n",
    "# function 2: counting the number of orthogroups for comparison from the updated list\n",
    "\n",
    "def countrowsNewDF(dataframe):\n",
    "    programPairs= {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        key1 = (row[1], row[2])\n",
    "        if key1 not in programPairs:\n",
    "            programPairs[key1] = []\n",
    "            programPairs[key1].append(row.tolist())\n",
    "        else:\n",
    "            programPairs[key1].append(row.tolist())\n",
    "    \n",
    "    countList = []\n",
    "    for pairKey, metricRow in programPairs.items():\n",
    "        print(pairKey)\n",
    "        columnNames = list(dataframe.columns)\n",
    "        progPairDF = pd.DataFrame(metricRow, columns = columnNames)\n",
    "        print(progPairDF.shape)\n",
    "        countList.append([pairKey,progPairDF.shape[0]])\n",
    "    \n",
    "    return(countList)\n",
    "\n",
    "# function 3: combine all the outputs into a summary dataframe\n",
    "\n",
    "def combineDF(metricsDF, ori_cts1_s, ori_cts1_d, newSameDF, newDiffDF):\n",
    "    intialSummary = getSummaryNumbers(metricsDF)\n",
    "    \n",
    "    oriCountSame_DF = pd.DataFrame(ori_cts1_s, columns=[\"programPair\",\"oriATgenes_same\"])\n",
    "    oriCountDiff_DF = pd.DataFrame(ori_cts1_d, columns=[\"programPair\",\"oriATgenes_diff\"])\n",
    "    \n",
    "    list_same = countrowsNewDF(newSameDF)\n",
    "    list_diff = countrowsNewDF(newDiffDF)\n",
    "    \n",
    "    newCountSame_DF = pd.DataFrame(list_same, columns=[\"programPair\",\"combAvg_same\"])\n",
    "    newCountDiff_DF = pd.DataFrame(list_diff, columns=[\"programPair\",\"combAvg_diff\"])\n",
    "    \n",
    "    listOfDF = [initialSummary, oriCountSame_DF, newCountSame_DF, oriCountDiff_DF, newCountDiff_DF]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['programPair']), listOfDF)\n",
    "    \n",
    "    df_merged[\"newTotalOG\"] = df_merged[\"oneAT\"] + df_merged[\"combAvg_same\"] + df_merged[\"combAvg_diff\"]\n",
    "    df_merged[\"oriTotal\"] = df_merged[\"oriATgenes_same\"] + df_merged[\"oriATgenes_diff\"] \n",
    "    \n",
    "    return(df_merged)\n",
    "\n",
    "################\n",
    "################\n",
    "## START HERE ##\n",
    "################\n",
    "################\n",
    "\n",
    "# call functions and create outputs\n",
    "\n",
    "main_path = r\"/path_to_files\"\n",
    "\n",
    "##############################\n",
    "## DIPLOID set of functions ##\n",
    "##############################\n",
    "\n",
    "# read in files\n",
    "print(\"read file\")\n",
    "dip_file = main_path + \"/diploid/output/diploid_pairwiseMetrics_240212.csv\"\n",
    "metrics_dip = pd.read_csv(dip_file)\n",
    "metrics_dip.replace('na', np.nan, inplace=True)\n",
    "\n",
    "subset_d = metrics_dip\n",
    "print(\"create Dictionary\")\n",
    "sameATnum_d, diffATnum_d = createDictionaries(subset_d)\n",
    "\n",
    "# for OG with different AT numbers\n",
    "print(\"for diff AT numbers\")\n",
    "print(\"inclusive AT key\")\n",
    "diff_newKeys_d = InclusiveATkey(diffATnum_d)\n",
    "checkNumGenes(diff_newKeys_d)\n",
    "print(\"update keys for diff\")\n",
    "programPairsDiff_update_d = updateKeys(diff_newKeys_d)\n",
    "print('check new gene numbers')\n",
    "checkNumGenes(programPairsDiff_update_d)\n",
    "print(\"create new dictionary of dictionaries with new AT keys\")\n",
    "newProgramPairsDiff_d = createNewDictionary(programPairsDiff_update_d)\n",
    "print(\"add values\")\n",
    "diffATvalue = addValuesToDictionaries(subset_d, newProgramPairsDiff_d)\n",
    "print(\"calc new avg\")\n",
    "diffOGList_d, oriATnum_diff_d = newAvgList(diffATvalue_d)\n",
    "\n",
    "# for OG with same AT numbers/gene composition\n",
    "print(\"for same AT numbers\")\n",
    "print(\"inclusive AT key - shouldn't change\")\n",
    "same_newKeys_d = InclusiveATkey(sameATnum_d)\n",
    "print(\" create new dicitonary of dictionaries with new AT keys\")\n",
    "newProgramPairsSame_d = createNewDictionary(same_newKeys_d)\n",
    "print(\"add values\")\n",
    "sameATvalue_d = addValuesToDictionaries(subset_d, newProgramPairsSame_d)\n",
    "print(\"calc new avg\")\n",
    "sameOGList_d, oriATnum_same_d = newAvgList(sameATvalue_d)\n",
    "\n",
    "#create dataframes for both datasets\n",
    "columnNames = [\"gene\",\"program1\",\"program2\",\"RS\",\"ARS\",\"intersection\",\"union\",\"Jaccard\",\"p1_num_AT\",\n",
    "                   \"p1_AT_genes\",\"p2_num_AT\",\"p2_AT_genes\"]\n",
    "\n",
    "sameOGdf_d = pd.DataFrame(sameOGList_d, columns=columnNames)\n",
    "diffOGdf_d = pd.DataFrame(diffOGList_d, columns=columnNames)\n",
    "\n",
    "sameOGdf_d_nodup = sameOGdf_d.drop_duplicates()\n",
    "diffOGdf_d_nodup = diffOGdf_d.drop_duplicates()\n",
    "\n",
    "# call function to create summary dataframe\n",
    "diploid_sum = combineDF(metrics_dip, oriATnum_same_d, oriATnum_diff_d, sameOGdf_d_nodup, diffOGdf_d_nodup)\n",
    "summaryOutput_d = main_path + \"/diploid/output/summary_diploid_240215.csv\"\n",
    "diploid_sum.to_csv(summaryOutput_d, index = False)\n",
    "\n",
    "# Creating the final updated metrics table for making heatmaps\n",
    "oneSubset_d = metrics_dip[(metrics_dip[\"p1_num_AT\"]== 1) & (metrics_dip[\"p2_num_AT\"] == 1)]\n",
    "oneSubset_d = oneSubset_d.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(oneSubset_d.shape)\n",
    "print(\"concatenate dataframes\")\n",
    "metrics_dfs_d = [oneSubset_d, sameOGdf_d_nodup, diffOGdf_d_nodup]\n",
    "metrics_merged_d = pd.concat(metrics_dfs_d)\n",
    "print(metrics_merged_d.shape)\n",
    "print(\"drop duplicates\")\n",
    "nodup_merged_d = metrics_merged_d.drop_duplicates()\n",
    "print(nodup_merged_d.shape)\n",
    "newMetricsNoDup_out_d = main_path + \"/diploid/output/diploid_newMetrics_noDup_240215.csv\"\n",
    "nodup_merged_d.to_csv(newMetricsNoDup_out_d, index=False)\n",
    "\n",
    "###########################\n",
    "## FULL set of functions ##\n",
    "###########################\n",
    "# read in files\n",
    "print(\"read file\")\n",
    "full_file = main_path + \"/fullset/output/full_pairwiseMetrics_240209.csv\"\n",
    "metrics_full = pd.read_csv(full_file)\n",
    "metrics_full.replace('na', np.nan, inplace=True)\n",
    "\n",
    "subset_f = metrics_full\n",
    "print(\"create Dictionary\")\n",
    "sameATnum_f, diffATnum_f = createDictionaries(subset_f)\n",
    "\n",
    "# for OG with different AT numbers\n",
    "print(\"for diff AT numbers\")\n",
    "print(\"inclusive AT key\")\n",
    "diff_newKeys_f = InclusiveATkey(diffATnum_f)\n",
    "checkNumGenes(diff_newKeys_f)\n",
    "print(\"update keys for diff\")\n",
    "programPairsDiff_update_f = updateKeys(diff_newKeys_f)\n",
    "print('check new gene numbers')\n",
    "checkNumGenes(programPairsDiff_update_f)\n",
    "print(\"create new dictionary of dictionaries with new AT keys\")\n",
    "newProgramPairsDiff_f = createNewDictionary(programPairsDiff_update_f)\n",
    "print(\"add values\")\n",
    "diffATvalue = addValuesToDictionaries(subset_f, newProgramPairsDiff_f)\n",
    "print(\"calc new avg\")\n",
    "diffOGList_f, oriATnum_diff_f = newAvgList(diffATvalue_f)\n",
    "\n",
    "# for OG with same AT numbers/gene composition\n",
    "print(\"for same AT numbers\")\n",
    "print(\"inclusive AT key - shouldn't change\")\n",
    "same_newKeys_f = InclusiveATkey(sameATnum_f)\n",
    "print(\" create new dicitonary of dictionaries with new AT keys\")\n",
    "newProgramPairsSame_f = createNewDictionary(same_newKeys_f)\n",
    "print(\"add values\")\n",
    "sameATvalue_f = addValuesToDictionaries(subset_f, newProgramPairsSame_f)\n",
    "print(\"calc new avg\")\n",
    "sameOGList_f, oriATnum_same_f = newAvgList(sameATvalue_f)\n",
    "\n",
    "#create dataframes for both datasets\n",
    "columnNames = [\"gene\",\"program1\",\"program2\",\"RS\",\"ARS\",\"intersection\",\"union\",\"Jaccard\",\"p1_num_AT\",\n",
    "                   \"p1_AT_genes\",\"p2_num_AT\",\"p2_AT_genes\"]\n",
    "\n",
    "sameOGdf_f = pd.DataFrame(sameOGList_f, columns=columnNames)\n",
    "diffOGdf_f = pd.DataFrame(diffOGList_f, columns=columnNames)\n",
    "\n",
    "sameOGdf_f_nodup = sameOGdf_f.drop_duplicates()\n",
    "diffOGdf_f_nodup = diffOGdf_f.drop_duplicates()\n",
    "\n",
    "# call function to create summary dataframe\n",
    "full_sum = combineDF(metrics_full, oriATnum_same_f, oriATnum_diff_f, sameOGdf_f_nodup, diffOGdf_f_nodup)\n",
    "summaryOutput_f = main_path + \"/fullset/output/summary_full_240215.csv\"\n",
    "full_sum.to_csv(summaryOutput_f, index = False)\n",
    "\n",
    "# Creating the final updated metrics table for making heatmaps\n",
    "oneSubset_f = metrics_full[(metrics_full[\"p1_num_AT\"]== 1) & (metrics_full[\"p2_num_AT\"] == 1)]\n",
    "oneSubset_f = oneSubset_f.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(oneSubset_f.shape)\n",
    "print(\"concatenate dataframes\")\n",
    "metrics_dfs_f = [oneSubset_f, sameOGdf_f_nodup, diffOGdf_f_nodup]\n",
    "metrics_merged_f = pd.concat(metrics_dfs_f)\n",
    "print(metrics_merged_d.shape)\n",
    "print(\"drop duplicates\")\n",
    "nodup_merged_f = metrics_merged_f.drop_duplicates()\n",
    "print(nodup_merged_f.shape)\n",
    "newMetricsNoDup_out_f = main_path + \"/fullset/output/full_newMetrics_noDup_240215.csv\"\n",
    "nodup_merged_f.to_csv(newMetricsNoDup_out_f, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
